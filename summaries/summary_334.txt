Federated learning enables training machine learning models on distributed datasets without centralizing the data, protecting privacy while still benefiting from large-scale data aggregation. Participating devices train local models on their data and share only model updates (not raw data) with a central server that aggregates them into a global model. This approach faces challenges including communication efficiency, handling non-identical data distributions across devices, and defending against malicious participants.